# LRBench++: A framework for effective learning rate tuning and benchmarking


If you find this tool useful, please cite the following paper:

    @INPROCEEDINGS{lrbenchplusplus,
        author={Jin, Hongpeng and Wei, Wenqi and Wang, Xuyu and Zhang, Wenbin and Wu, Yanzhao},
        booktitle={2023 IEEE Fifth International Conference on Cognitive Machine Intelligence (CogMI)},
        title={Demystifying Learning Rate Policies for High Accuracy Training of Deep Neural Networks},
        year={2023},
        volume={},
        number={},
        pages={},  
        doi={}
    }

    @article{lrbench-tist,
        author = {Wu, Yanzhao and Liu, Ling},
        title = {Selecting and Composing Learning Rate Policies for Deep Neural Networks},
        year = {2022},
        publisher = {Association for Computing Machinery},
        address = {New York, NY, USA},
        issn = {2157-6904},
        url = {https://doi.org/10.1145/3570508},
        doi = {10.1145/3570508},
        journal = {ACM Trans. Intell. Syst. Technol.},
        month = {11},
    }

    @INPROCEEDINGS{lrbench2019,
        author={Wu, Yanzhao and Liu, Ling and Bae, Juhyun and Chow, Ka-Ho and Iyengar, Arun and Pu, Calton and Wei, Wenqi and Yu, Lei and Zhang, Qi},
        booktitle={2019 IEEE International Conference on Big Data (Big Data)},
        title={Demystifying Learning Rate Policies for High Accuracy Training of Deep Neural Networks},
        year={2019},
        volume={},
        number={},
        pages={1971-1980},  
        doi={10.1109/BigData47090.2019.9006104}
    }

